scale_color_discrete(name="Country Name(second layer is o)") +
facet_wrap( ~ continent, nrow=4)
gapminder %>%
dplyr::filter( continent=="Africa" | continent=="Americas" | continent == "Asia" | continent == "Europe") %>%
dplyr::filter( substr(country,2,2)=="o" ) %>%
ggplot( aes(x=year, y=gdpPercap, color=country) ) +
geom_point() +
geom_smooth() +
labs(title="GDP per captia from 1957 to 2007", x="Year", y="GDP per captia") +
theme_bw() +
theme(plot.title=element_text(size=20, face="italic"),
axis.text.x=element_text(size=10),
axis.text.y=element_text(size=10),
axis.title.x=element_text(size=20),
axis.title.y=element_text(size=20)) +
scale_color_discrete(name="Country Name(second layer is o)") +
facet_wrap( ~ continent, nrow=4)
# And later save it to a stored figure
ggsave("myfirstplot.png", plot=plot1, width=25,
height=20, units="cm", dpi=400)
plot1 <- gapminder %>%
dplyr::filter( continent=="Africa" | continent=="Americas" | continent == "Asia" | continent == "Europe") %>%
dplyr::filter( substr(country,2,2)=="o" ) %>%
ggplot( aes(x=year, y=gdpPercap, color=country) ) +
geom_point() +
geom_smooth() +
labs(title="GDP per captia from 1957 to 2007", x="Year", y="GDP per captia") +
theme_bw() +
theme(plot.title=element_text(size=20, face="italic"),
axis.text.x=element_text(size=10),
axis.text.y=element_text(size=10),
axis.title.x=element_text(size=20),
axis.title.y=element_text(size=20)) +
scale_color_discrete(name="Country Name(second layer is o)") +
facet_wrap( ~ continent, nrow=4)
# And later save it to a stored figure
ggsave("myfirstplot.png", plot=plot1, width=25,
height=20, units="cm", dpi=400)
library(rgdal)
library(ggplot2)
library(plyr)
library(dplyr)
library(ggsn)
library(raster)
library(ggmap)
library(mapproj)
install.packages("raster")
# Location of the .shp file
Local_path <- "China_map/"
# Read china map, a shape file
China_map <- rgdal::readOGR(paste0(Local_path, "bou2_4p.shp"))
# Location of the .shp file
Local_path <- "China_map/"
# Read china map, a shape file
China_map <- rgdal::readOGR(paste0(Local_path, "bou2_4p.shp"))
library(rgdal)
library(ggplot2)
library(plyr)
library(dplyr)
library(ggsn)
library(raster)
library(ggmap)
library(mapproj)
# Location of the .shp file
Local_path <- "China_map/"
# Read china map, a shape file
China_map <- rgdal::readOGR(paste0(Local_path, "bou2_4p.shp"))
# Check the attributes
class(China_map)
# Show variable names
names(China_map)
# Check the attributes, use the operator @
map_data <- China_map@data
head(map_data)
# Convert characters to simple Chinese
China_map$NAME <- iconv(China_map$NAME, "GBK")
# Check the attributes, use the operator @
map_data <- China_map@data
head(map_data)
# Location of the .shp file
Local_path <- "China_map/"
# Read china map, a shape file
China_map <- rgdal::readOGR(paste0(Local_path, "bou2_4p.shp"))
# Check the attributes
class(China_map)
devtools::install_github('oswaldosantos/ggsn')
devtools::install_github('oswaldosantos/ggsn')
devtools::install_github('oswaldosantos/ggsn')
devtools::install_github('oswaldosantos/ggsn',force = TRUE)
library(ggpubr)
library(nortest)
library(geoR)
library(ggplot2)
before <- c(6.56,4.13,5.09,4.71,6.01,5.53,4.94,5.97,5.09,4.69,5.49,6.65,6.17,7.83,6.22,5.08
6.45,6.40,5.29,5.42,6.68,6.00,4.88,6.08,4.82,8.97,5.88,6.19,5.86,5.01,5.81,7.63)
before <- c(6.56,4.13,5.09,4.71,6.01,5.53,4.94,5.97,5.09,4.69,5.49,6.65,6.17,7.83,6.22,5.08,
6.45,6.40,5.29,5.42,6.68,6.00,4.88,6.08,4.82,8.97,5.88,6.19,5.86,5.01,5.81,7.63)
after <- c(6.12,4.59,5.33,5.83,5.34,5.37,5.29,5.55,5.80,5.22,5.29,4.84,2.35,5.04,3.60,4.08,
5.11,5.76,5.48,4.96,5.51,4.46,5.52,5.35,5.19,4.88,5.91,6.57,6.74,5.18,5.98,5.51)
# Lilliefors test of sample 1
lillie.test(before)
lillie.test(after)
t.test(before, after, alternative="less", paired=T)
t.test(before, after, alternative="greater", paired=T)
t.test(before, after, alternative="less", paired=T)
mean(before)-mean(after)
(mean(before)-mean(after))/mean(before)
t.test(before, after, alternative="less", paired=F)
t.test(before, after, alternative="greater", paired=F)
A <- c(73,102,118,104,98,107,100,87,117,111)
B <- c(98,74,56,111,95,88,82,77,86,92)
C <- c(94,79,96,95,102,102,108,91,120,105)
D <- c(97,103,90,99,103,109,108,101,98,115)
# Make data frame
O2_data  <- data.frame(O2=c(A,B,C,D),
group=c(rep("A", length(A)),
rep("B", length(B)),
rep("C", length(C)),
rep("D", length(D))) )
oneway.test(O2 ~ group, data=O2_data, var.equal=T)
res_aov <- aov(O2 ~ group, data=O2_data)
summary(res_aov)
# Plot the 95% (default) CI of the difference
plot(TukeyHSD(res_aov))
# Post-hoc test with the Hukey test
TukeyHSD(res_aov)
library(GGally)
library(olsrr)
AQI <- C(377,307,280,388,268,347,308,247,289,200,329,385,337,336,384)
P <- c(999.9,999.4,999.1,999.6,998.5,1000.8,1002.0,999.4,1002.7,
1003.2,996.6,1003.0,1004.3,1000.4,998.3)
AQI <- C(377,307,280,388,268,347,308,247,289,200,329,385,337,336,384)
AQI <- C(377,307,280,388,268,347,308,247,289,200,329,385,337,336,384)
AQI <- c(377,307,280,388,268,347,308,247,289,200,329,385,337,336,384)
P <- c(999.9,999.4,999.1,999.6,998.5,1000.8,1002.0,999.4,1002.7,
1003.2,996.6,1003.0,1004.3,1000.4,998.3)
Tem <- c(20.2,21.1,19.3,17.5,16.9,22.5,13.6,21.2,23.5,18.6,25.0,23.6,
17.0,27.2,14.1)
Hum <- c(44,56,20,31,60,48,76,65,60,74,68,69,50,36,63)
Traffic <- c(357,256,270,541,254,337,411,280,289,88,275,358,380,268,523)
# Fit the full model, where all independent variables are included
full_model  <- lm(AQI ~ P + Tem + Hum + Traffic)
# Test all possible subsets
output      <- ols_step_all_possible(full_model)
# Print results from all possible subsets
output
ols_step_backward_aic(full_model, details=F)
# Best model
reg <- lm(AQI ~ Tem + Traffic)
summary(reg)
6.40475*25+0.48960*450
6.40475*15+0.48960*300
co2_data <- read.csv(file = "co2_monthly_mlo_1990_2024",header=T)
# Read ozone and meteorological data
co2_data <- read.csv(file = "ozone_data.csv", header=T)
co2_data <- read.csv(file = "co2_monthly_mlo_1990_2024.csv",header=T)
library(dplyr)
library(lubridate)
library(forecast)
co2_data <- read.csv(file = "co2_monthly_mlo_1990_2024.csv",header=T)
# Check the variable names
head(co2_data)
# Convert the data.frame to a tibble
co2_tbl <- as_tibble(co2_data)
# Show data
co2_tbl
function(as.Date())
function(as.Date)
# Show data
co2_db1
co2_data <- read.csv(file = "co2_monthly_mlo_1990_2024.csv",header=T)
# Check the variable names
head(co2_data)
# Convert the data.frame to a tibble
co2_tbl <- as_tibble(co2_data)
# Show data
co2_db1
co2_data <- read.csv(file = "co2_monthly_mlo_1990_2024.csv",header=T)
# Check the variable names
head(co2_data)
# Convert the data.frame to a tibble
co2_tbl <- as_tibble(co2_data)
# Show data
co2_tb1
# Show data
co2_tbl
# Get global daily new cases
co2_tbl <- co2_tbl %>%
group_by(Month) %>%
summarize(co2 = sum(CO2_ppm))
# Get global daily new cases
co2_tbl <- co2_tbl %>%
mutate(Month = sum(Month)) %>%
group_by(Month) %>%
summarize(co2 = sum(CO2_ppm))
# Quick plot
plot(COVID_tbl$dateRep,COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
# Quick plot
plot(co2_tbl$Date,co2_tbl$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
co2_data <- read.csv(file = "co2_monthly_mlo_1990_2024.csv",header=T)
# Quick plot
plot(co2_tbl$Date,co2_tbl$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Quick plot
plot(co2_data$Date,co2_data$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
co2_data <- read.csv(file = "co2_monthly_mlo_1990_2024.csv",header=T)
# Quick plot
plot(co2_data$Date,co2_data$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Filter the data, only use data from April 01
co2_tbl <- co2_data %>%
filter(co2_data$CO2_ppm != 999.9)
# Show data
COVID_tbl
# Show data
co2_tbl
# Quick plot
plot(co2_data$Date,co2_data$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Quick plot
plot(co2_tbl$Date,co2_tbl$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Filter the data, only use data from April 01
co2_tbl <- co2_data %>%
filter(co2_data$CO2_ppm != 999.9)
# Show data
co2_tbl
# Quick plot
plot(co2_tbl$Date,co2_tbl$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Start date of the time series, read from the .csv file
Date_start <- 1990.0417
# End date of the time series, read from the .csv file
Date_end   <- 2024.0417
# Get the Julian Day of the start and end date
N_days     <- Date_end - Date_start + 1
# Convert the vector data to a time series
global_cases_ts <- ts(co2_tbl$CO2_ppm[1:N_days], start=c(1990,JD_start), frequency=12)
# Check structure
str(co2_tbl)
# Data transform with log
global_cases_ts_log <- log(co2_tbl)
# Convert the vector data to a time series
global_cases_ts <- ts(co2_tbl$CO2_ppm, frequency=12)
# Data transform with log
global_cases_ts_log <- log(global_cases_ts)
# Check acf and pacf
acf(global_cases_ts_log)
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Check acf and pacf
acf(global_cases_ts_log_d1)
pacf(global_cases_ts_log_d1)
# Automated forecasting using an ARIMA model
model <- auto.arima(global_cases_ts_log)
# Show details of the ARIMA model
model
# Quick plot
plot(co2_tbl$Date,co2_tbl$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Filter the data, only use data from April 01
co2_tbl <- co2_data %>%
filter(co2_data$CO2_ppm != 999.9)
# Show data
co2_tbl
# Quick plot
plot(co2_tbl$Date,co2_tbl$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Filter the data, only use data from April 01
co2_tbl <- filter(co2_data$CO2_ppm != 999.9)
# Filter the data, only use data from April 01
co2_data <- co2_data %>%
filter(co2_data$CO2_ppm != 999.9)
# Show data
co2_data
# Filter the data, only use data from April 01
co2_tbl <- subset(co2_data, co2_data$CO2_ppm != 999.9)
# Show data
co2_tbl
# Filter the data, only use data from April 01
co2_tbl <- subset(co2_data, co2_data$CO2_ppm != 999.99)
# Show data
co2_tbl
# Quick plot
plot(co2_tbl$Date,co2_tbl$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Filter the data, only use data from April 01
co2_tbl1 <- subset(co2_tbl, co2_tbl$Date >= 2023.7917)
# Start date of the time series, read from the .csv file
Date_start <- 2023.7917
# End date of the time series, read from the .csv file
Date_end   <- 2024.0417
# Get the Julian Day of the start and end date
N_days     <- 4
# Convert the vector data to a time series
global_cases_ts <- ts(co2_tbl$CO2_ppm, frequency=12)
# Check acf and pacf
acf(global_cases_ts_log)
pacf(global_cases_ts_log)
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Check acf and pacf
acf(global_cases_ts_log_d1)
pacf(global_cases_ts_log_d1)
# Automated forecasting using an ARIMA model
model <- auto.arima(global_cases_ts_log)
# Show details of the ARIMA model
model
# Convert the vector data to a time series
global_cases_ts <- ts(co2_tbl1$CO2_ppm, frequency=12)
# Data transform with log
global_cases_ts_log <- log(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts_log, type="l")
# Check acf and pacf
acf(global_cases_ts_log)
pacf(global_cases_ts_log)
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Check acf and pacf
acf(global_cases_ts_log_d1)
pacf(global_cases_ts_log_d1)
library(dplyr)
library(lubridate)
library(forecast)
# Read in the COVID-19 data
COVID_data <- read.csv(file = "COVID_2020_data.csv", header = T)
# Check the variable names
head(COVID_data)
# Convert the data.frame to a tibble
COVID_tbl <- as_tibble(COVID_data)
# Show data
COVID_tbl
# Get global daily new cases
COVID_tbl <- COVID_tbl %>%
mutate(dateRep = as.Date(dateRep,format='%d/%m/%Y')) %>%
group_by(dateRep) %>%
summarize(global_cases = sum(cases))
# Show data
COVID_tbl
# Quick plot
plot(COVID_tbl$dateRep,COVID_tbl$global_cases,
type="l", xlab="Date", ylab="Global cases")
# Filter the data, only use data from April 01
COVID_tbl <- COVID_tbl %>%
filter(dateRep >= as.Date("2020-04-01"))
# Show data
COVID_tbl
# Start date of the time series, read from the .csv file
Date_start <- as.Date("2020-04-01")
# End date of the time series, read from the .csv file
Date_end   <- as.Date("2020-11-09")
# Get the Julian Day of the start and end date
JD_start   <- yday(Date_start)
JD_end     <- yday(Date_end)
N_days     <- JD_end - JD_start + 1
# Convert the vector data to a time series
global_cases_ts <- ts(COVID_tbl$global_cases[1:N_days], start=c(2020,JD_start), frequency=365)
# The indicator of the time series
inds            <- seq(Date_start, Date_end, by="day")
# Check structure
str(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts, type="l")
# Data transform with log
global_cases_ts_log <- log(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts_log, type="l")
# Check acf and pacf
acf(global_cases_ts_log)
# Start date of the time series, read from the .csv file
Date_start <- as.Date("2020-04-01")
# End date of the time series, read from the .csv file
Date_end   <- as.Date("2020-11-09")
# Get the Julian Day of the start and end date
JD_start   <- yday(Date_start)
JD_end     <- yday(Date_end)
N_days     <- JD_end - JD_start + 1
# Convert the vector data to a time series
global_cases_ts <- ts(COVID_tbl$global_cases[1:N_days], start=c(2020,JD_start), frequency=365)
# The indicator of the time series
inds            <- seq(Date_start, Date_end, by="day")
# Check structure
str(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts, type="l")
co2_data <- read.csv(file = "co2_monthly_mlo_1990_2024.csv",header=T)
# Quick plot
plot(co2_data$Date,co2_data$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Filter the data, only use data from April 01
co2_tbl <- subset(co2_data, co2_data$CO2_ppm != 999.99)
# Show data
co2_tbl
# Quick plot
plot(co2_tbl$Date,co2_tbl$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Filter the data, only use data from April 01
co2_tbl1 <- subset(co2_tbl, co2_tbl$Date >= 2023.7917)
# Start date of the time series, read from the .csv file
Date_start <- 2023.7917
# End date of the time series, read from the .csv file
Date_end   <- 2024.0417
# Get the Julian Day of the start and end date
N_days     <- 4
# Start date of the time series, read from the .csv file
Date_start <- 1990.0417
# End date of the time series, read from the .csv file
Date_end   <- 2024.0417
# Get the Julian Day of the start and end date
N_days     <- 409
# Convert the vector data to a time series
global_cases_ts <- ts(co2_tbl$CO2_ppm, frequency=12)
# Data transform with log
global_cases_ts_log <- log(global_cases_ts)
# Plot time series
plot(inds, global_cases_ts_log, type="l")
# Check acf and pacf
acf(global_cases_ts_log)
pacf(global_cases_ts_log)
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Check acf and pacf
acf(global_cases_ts_log_d1)
pacf(global_cases_ts_log_d1)
# Automated forecasting using an ARIMA model
model <- auto.arima(global_cases_ts_log)
# Show details of the ARIMA model
model
co2_data <- read.csv(file = "co2_monthly_mlo_1990_2024.csv",header=T)
# Quick plot
plot(co2_data$Date,co2_data$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Filter the data, only use data from April 01
co2_tbl <- subset(co2_data, co2_data$CO2_ppm != 999.99)
# Show data
co2_tbl
# Quick plot
plot(co2_tbl$Date,co2_tbl$CO2_ppm,
type="l", xlab="Date", ylab="CO2 ppm")
# Start date of the time series, read from the .csv file
Date_start <- 1990.0417
# End date of the time series, read from the .csv file
Date_end   <- 2024.0417
# Get the Julian Day of the start and end date
N_days     <- 409
# Plot time series
plot(inds, global_cases_ts_log, type="l")
pacf(global_cases_ts_log)
# Take the diff, d=1
global_cases_ts_log_d1 <- diff(global_cases_ts_log)
# Convert the vector data to a time series
global_cases_ts <- ts(co2_tbl$CO2_ppm, frequency=12)
# Data transform with log
global_cases_ts_log <- log(global_cases_ts)
# Check acf and pacf
acf(global_cases_ts_log)
# Plot time series
plot(global_cases_ts_log_d1,type="l")
# Check acf and pacf
acf(global_cases_ts_log_d1)
pacf(global_cases_ts_log_d1)
# Automated forecasting using an ARIMA model
model <- auto.arima(global_cases_ts_log)
# Show details of the ARIMA model
model
# Number of days to predict
days_forecast  <- 1
# Number of include in the plot
days_in_plot   <- 1
# Make predictions using the forecast() function
forecast_30days <- forecast(model, days_forecast)
# Number of days to predict
days_forecast  <- 3
# Number of include in the plot
days_in_plot   <- 3
# Make predictions using the forecast() function
forecast_30days <- forecast(model, days_forecast)
# Plot
plot(forecast_30days, include=days_in_plot,
xlab="Time", ylab="log(global cases)", type="o", lwd=2)
forecast_30days
exp(6.048781)
exp(6.049388)
exp(6.053131)
---
title: "My Website"
rmarkdown::render_site()
setwd
getwd()
setwd(D:/Amber/nike/class/ESE335)
setwd("D:/Amber/nike/class/ESE335")
rmarkdown::render_site()
setwd("D:/Amber/nike/class/ESE335")
rmarkdown::render_site()
setwd("D:\Amber\nike\class\ESE335\github\kulongyanzi")
setwd("D:/Amber/nike/class/ESE335/github/kulongyanzi")
rmarkdown::render_site()
<img src="figs/DSC03433.png" alt="drawing" width="500"/>
rmarkdown::render_site()
rmarkdown::render_site()
